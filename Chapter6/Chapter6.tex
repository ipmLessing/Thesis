\chapter{Results and Discussion}\label{ch:6}
\minitoc

Conclusions. Sample of citation in ``mpUnsrt'' style, derived from the standard {Bib\TeX} ``unsrt'' style.

\newpage

\section{Perception Module Performance}

Discuss YOLOv8's strengths and limitations for gate detection in synthetic and real-world scenarios.


Analyze the effectiveness of Blender and Grounding DINO in addressing data limitations.


\section{SOH Prediction Module Performance}

Present Bi-LSTM accuracy metrics and their implications for SOH-aware decision-making.


\section{Insights from Conceptual RL Framework}

Analyze the theoretical trade-offs highlighted in the simulated RL framework:

Evaluate reward balancing and mode-switching outcomes.

Identify potential challenges for real-world implementation.


\section{Scalability and Generalization}

Discuss how the framework scales to different platforms or battery chemistries.

Highlight strategies for generalizing synthetic data findings to real-world applications.


\section{Ethical and Safety Considerations}

Reflect on safety mechanisms (e.g., fail-safes) and ethical issues in deploying the framework.


\section{Perception Case Study: Drone Racing}

Present results from YOLOv8-based perception:

Compare accuracy between real-world and synthetic data (e.g., 75\% vs. 65\%).

Highlight the impact of Blender and Grounding DINO on model performance.

\section{Proof-of-Concept Simulation for the Reinforcement Learning Framework}

Simulate a simplified scenario where perception and SOH predictions are used to inform high-level decision-making.

Use existing datasets to demonstrate how the \gls{RL} architecture could function in practice, focusing on:

Mode-switching behavior.

Trade-offs between performance and \gls{SOH} metrics.

\endinput